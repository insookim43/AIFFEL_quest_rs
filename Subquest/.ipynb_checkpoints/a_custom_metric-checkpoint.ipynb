{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3c270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preliminary\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36219a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load imdb data\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471cf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "# define model\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(4, activation=\"relu\"),\n",
    "        layers.Dense(4, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3255dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b520f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "    \n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc568d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"F1score_user\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.predicted_positives = self.add_weight(name=\"predicted_positives\", initializer=\"zeros\") \n",
    "        self.actual_positives = self.add_weight(name=\"actual_positives\", initializer=\"zeros\")\n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.cast(y_pred > 0.5, \"float32\")\n",
    "        y_true = tf.cast(y_true, \"float32\")\n",
    "\n",
    "        actual_positives = tf.reduce_sum(y_true)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        predicted_positives = tf.reduce_sum(y_pred_classes)\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.predicted_positives.assign_add(predicted_positives)     \n",
    "        self.actual_positives.assign_add(actual_positives)     \n",
    "    \n",
    "    def result(self):\n",
    "        precision = ( tf.cast(self.true_positives, tf.float32) \n",
    "              / tf.cast(self.predicted_positives, tf.float32) + tf.keras.backend.epsilon())\n",
    "        recall = ( tf.cast(self.true_positives, tf.float32) \n",
    "              / tf.cast(self.actual_positives, tf.float32) + tf.keras.backend.epsilon())\n",
    "        return  (2 * recall * precision) / (recall + precision + tf.keras.backend.epsilon())\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.predicted_positives.assign(0)\n",
    "        self.actual_positives.assign(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb42cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class acc_user(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"acc_user\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.predicted_positives = self.add_weight(name=\"predicted_positives\", initializer=\"zeros\") \n",
    "        self.actual_positives = self.add_weight(name=\"actual_positives\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"true_negatives\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "#         tp + tn / tp + fp + tn + fn = acc\n",
    "#         tp + fp = p.p\n",
    "#         tp + fn = a.p\n",
    "#         tn             \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.cast(y_pred > 0.5, \"float32\")\n",
    "        y_true = tf.cast(y_true, \"float32\")\n",
    "               \n",
    "        actual_positives = tf.reduce_sum(y_true)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        predicted_positives = tf.reduce_sum(y_pred_classes)\n",
    "        # false_negatives = tf.reduce_sum(y_true.shape[0] - predicted_positives - (y_true.shape[0]-y_true))\n",
    "        # all samples - p.p - tn\n",
    "        # tn = !y_true\n",
    "        #true_negatives = tf.reduce_sum(tf.constant(1, dtype=\"float32\") -y_true)\n",
    "        true_negatives = tf.reduce_sum((1 -y_true)*(1-y_pred_classes))\n",
    "        total_samples = tf.shape(y_pred)[0]\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.predicted_positives.assign_add(predicted_positives)     \n",
    "        self.actual_positives.assign_add(actual_positives)     \n",
    "        self.true_negatives.assign_add(true_negatives)\n",
    "        self.total_samples.assign_add(total_samples)    \n",
    "        \n",
    "    def result(self):\n",
    "\n",
    "        return  (self.true_positives+self.true_negatives)/(tf.cast(self.total_samples, tf.float32) + tf.keras.backend.epsilon())\n",
    "        #return self.total_samples\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.predicted_positives.assign(0)\n",
    "        self.actual_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.total_samples.assign(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e27a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tp(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"tp\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.predicted_positives = self.add_weight(name=\"predicted_positives\", initializer=\"zeros\") \n",
    "        self.actual_positives = self.add_weight(name=\"actual_positives\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"true_negatives\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "#         tp + tn / tp + fp + tn + fn = acc\n",
    "#         tp + fp = p.p\n",
    "#         tp + fn = a.p\n",
    "#         tn \n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.cast(y_pred > 0.5, \"float32\")\n",
    "        y_true = tf.cast(y_true, \"float32\")\n",
    "        \n",
    "        \n",
    "        actual_positives = tf.reduce_sum(y_true)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        predicted_positives = tf.reduce_sum(y_pred_classes)\n",
    "        # false_negatives = tf.reduce_sum(y_true.shape[0] - predicted_positives - (y_true.shape[0]-y_true))\n",
    "        # all samples - p.p - tn\n",
    "        # tn = !y_true\n",
    "        true_negatives = tf.reduce_sum((1 -y_true)*(1-y_pred_classes))\n",
    "        total_samples = tf.shape(y_pred)[0]\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.predicted_positives.assign_add(predicted_positives)     \n",
    "        self.actual_positives.assign_add(actual_positives)     \n",
    "        self.true_negatives.assign_add(true_negatives)\n",
    "        self.total_samples.assign_add(total_samples)    \n",
    "        \n",
    "    def result(self):\n",
    "\n",
    "        #return  (self.true_positives+self.true_negatives)/(tf.cast(self.total_samples, tf.float32) + tf.keras.backend.epsilon())\n",
    "        return self.true_positives\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.predicted_positives.assign(0)\n",
    "        self.actual_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.total_samples.assign(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850da28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tn(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"tn\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.predicted_positives = self.add_weight(name=\"predicted_positives\", initializer=\"zeros\") \n",
    "        self.actual_positives = self.add_weight(name=\"actual_positives\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"true_negatives\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "#         tp + tn / tp + fp + tn + fn = acc\n",
    "#         tp + fp = p.p\n",
    "#         tp + fn = a.p\n",
    "#         tn \n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.cast(y_pred > 0.5, \"float32\")\n",
    "        y_true = tf.cast(y_true, \"float32\")\n",
    "                \n",
    "        actual_positives = tf.reduce_sum(y_true)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        predicted_positives = tf.reduce_sum(y_pred_classes)\n",
    "        # false_negatives = tf.reduce_sum(y_true.shape[0] - predicted_positives - (y_true.shape[0]-y_true))\n",
    "        # all samples - p.p - tn\n",
    "        # tn = !y_true\n",
    "        true_negatives = tf.reduce_sum((1 -y_true)*(1-y_pred_classes))\n",
    "        total_samples = tf.shape(y_pred)[0]\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.predicted_positives.assign_add(predicted_positives)     \n",
    "        self.actual_positives.assign_add(actual_positives)     \n",
    "        self.true_negatives.assign_add(true_negatives)\n",
    "        self.total_samples.assign_add(total_samples)    \n",
    "        \n",
    "    def result(self):\n",
    "\n",
    "        #return  (self.true_positives+self.true_negatives)/(tf.cast(self.total_samples, tf.float32) + tf.keras.backend.epsilon())\n",
    "        return self.true_negatives\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.predicted_positives.assign(0)\n",
    "        self.actual_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.total_samples.assign(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c16d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b92aa539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score2(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"F1score_user2\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"true_negatives\", initializer=\"zeros\") \n",
    "        self.false_positives = self.add_weight(name=\"false_positives\", initializer=\"zeros\")\n",
    "        self.false_negatives = self.add_weight(name=\"false_negatives\", initializer=\"zeros\")\n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.squeeze(tf.cast(y_pred > 0.5, \"float32\"))\n",
    "        y_true = tf.squeeze(tf.cast(y_true, \"float32\"))\n",
    "\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        true_negatives = tf.reduce_sum((1 -y_true)*(1-y_pred_classes))\n",
    "        false_positives = tf.reduce_sum(tf.cast(((y_pred_classes == 1) & (y_true == 0)), tf.float32))\n",
    "        false_negatives = tf.reduce_sum(tf.cast( ((y_pred_classes == 0) & (y_true == 1)), tf.float32))\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.true_negatives.assign_add(true_negatives)     \n",
    "        self.false_positives.assign_add(false_positives)     \n",
    "        self.false_negatives.assign_add(false_negatives)     \n",
    "    \n",
    "    def result(self):\n",
    "        precision = tf.cast(self.true_positives, \"float32\")/ (tf.cast(self.true_positives, \"float32\")+ tf.cast(self.false_positives, \"float32\")+ tf.keras.backend.epsilon())\n",
    "                \n",
    "        recall = tf.cast(self.true_positives, \"float32\")/ (tf.cast(self.true_positives, \"float32\")+ tf.cast(self.false_negatives, \"float32\")+ tf.keras.backend.epsilon())\n",
    "                \n",
    "        return  (2 * recall * precision) / (recall + precision + tf.keras.backend.epsilon())\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.false_negatives.assign(0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "374604b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fp2(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"fp2\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"true_negatives\", initializer=\"zeros\") \n",
    "        self.false_positives = self.add_weight(name=\"false_positives\", initializer=\"zeros\")\n",
    "        self.false_negatives = self.add_weight(name=\"false_negatives\", initializer=\"zeros\")\n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.squeeze(tf.cast(y_pred > 0.5, \"float32\"))\n",
    "        y_true = tf.squeeze(tf.cast(y_true, \"float32\"))\n",
    "\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        true_negatives = tf.reduce_sum((1 -y_true)*(1-y_pred_classes))\n",
    "        false_positives = tf.reduce_sum(tf.cast( ((y_pred_classes == 1) & (y_true == 0)), tf.float32))\n",
    "        false_negatives = tf.reduce_sum(tf.cast( ((y_pred_classes == 0) & (y_true == 1)), tf.float32))\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.true_negatives.assign_add(true_negatives)     \n",
    "        self.false_positives.assign_add(false_positives)     \n",
    "        self.false_negatives.assign_add(false_negatives)\n",
    "    \n",
    "    def result(self):\n",
    "        return  self.false_positives\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.false_negatives.assign(0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e8a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fn2(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"fn2\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"true_negatives\", initializer=\"zeros\") \n",
    "        self.false_positives = self.add_weight(name=\"false_positives\", initializer=\"zeros\")\n",
    "        self.false_negatives = self.add_weight(name=\"false_negatives\", initializer=\"zeros\")\n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.squeeze(tf.cast(y_pred > 0.5, \"float32\"))\n",
    "        y_true = tf.squeeze(tf.cast(y_true, \"float32\"))\n",
    "\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        true_negatives = tf.reduce_sum((1 -y_true)*(1-y_pred_classes))\n",
    "        false_positives = tf.reduce_sum(tf.cast( ((y_pred_classes == 1) & (y_true == 0)), tf.float32))\n",
    "        false_negatives = tf.reduce_sum(tf.cast( ((y_pred_classes == 0) & (y_true == 1)), tf.float32))\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.true_negatives.assign_add(true_negatives)     \n",
    "        self.false_positives.assign_add(false_positives)     \n",
    "        self.false_negatives.assign_add(false_negatives)     \n",
    "    \n",
    "    def result(self):\n",
    "\n",
    "        return  self.false_negatives\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.false_negatives.assign(0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8769cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_new = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55d6c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                 metrics=[\"accuracy\", acc_user(), F1Score(), F1Score2(), tp(), tn(), fp2(), fn2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7833bc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 0.4382 - accuracy: 0.8195 - acc_user: 0.8195 - F1score_user: 0.8191 - F1score_user2: 0.8191 - tp: 6127.0000 - tn: 6166.0000 - fp2: 1301.0000 - fn2: 1406.0000 - val_loss: 0.3456 - val_accuracy: 0.8687 - val_acc_user: 0.8687 - val_F1score_user: 0.8711 - val_F1score_user2: 0.8711 - val_tp: 4436.0000 - val_tn: 4251.0000 - val_fp2: 782.0000 - val_fn2: 531.0000\n",
      "Epoch 2/20\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2762 - accuracy: 0.8960 - acc_user: 0.8960 - F1score_user: 0.8982 - F1score_user2: 0.8982 - tp: 6880.0000 - tn: 6560.0000 - fp2: 907.0000 - fn2: 653.0000 - val_loss: 0.3137 - val_accuracy: 0.8837 - val_acc_user: 0.8837 - val_F1score_user: 0.8864 - val_F1score_user2: 0.8864 - val_tp: 4539.0000 - val_tn: 4298.0000 - val_fp2: 735.0000 - val_fn2: 428.0000\n",
      "Epoch 3/20\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2314 - accuracy: 0.9163 - acc_user: 0.9163 - F1score_user: 0.9178 - F1score_user2: 0.9178 - tp: 7012.0000 - tn: 6732.0000 - fp2: 735.0000 - fn2: 521.0000 - val_loss: 0.3135 - val_accuracy: 0.8893 - val_acc_user: 0.8893 - val_F1score_user: 0.8890 - val_F1score_user2: 0.8890 - val_tp: 4432.0000 - val_tn: 4461.0000 - val_fp2: 572.0000 - val_fn2: 535.0000\n",
      "Epoch 4/20\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2098 - accuracy: 0.9256 - acc_user: 0.9256 - F1score_user: 0.9267 - F1score_user2: 0.9267 - tp: 7058.0000 - tn: 6826.0000 - fp2: 641.0000 - fn2: 475.0000 - val_loss: 0.3238 - val_accuracy: 0.8912 - val_acc_user: 0.8912 - val_F1score_user: 0.8907 - val_F1score_user2: 0.8907 - val_tp: 4433.0000 - val_tn: 4479.0000 - val_fp2: 554.0000 - val_fn2: 534.0000\n",
      "Epoch 5/20\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1975 - accuracy: 0.9324 - acc_user: 0.9324 - F1score_user: 0.9334 - F1score_user2: 0.9334 - tp: 7104.0000 - tn: 6882.0000 - fp2: 585.0000 - fn2: 429.0000 - val_loss: 0.3371 - val_accuracy: 0.8883 - val_acc_user: 0.8883 - val_F1score_user: 0.8909 - val_F1score_user2: 0.8909 - val_tp: 4560.0000 - val_tn: 4323.0000 - val_fp2: 710.0000 - val_fn2: 407.0000\n",
      "Epoch 6/20\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1892 - accuracy: 0.9355 - acc_user: 0.9355 - F1score_user: 0.9363 - F1score_user2: 0.9363 - tp: 7104.0000 - tn: 6929.0000 - fp2: 538.0000 - fn2: 429.0000 - val_loss: 0.3436 - val_accuracy: 0.8898 - val_acc_user: 0.8898 - val_F1score_user: 0.8901 - val_F1score_user2: 0.8901 - val_tp: 4461.0000 - val_tn: 4437.0000 - val_fp2: 596.0000 - val_fn2: 506.0000\n",
      "Epoch 7/20\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1825 - accuracy: 0.9405 - acc_user: 0.9405 - F1score_user: 0.9412 - F1score_user2: 0.9412 - tp: 7145.0000 - tn: 6962.0000 - fp2: 505.0000 - fn2: 388.0000 - val_loss: 0.3658 - val_accuracy: 0.8885 - val_acc_user: 0.8885 - val_F1score_user: 0.8878 - val_F1score_user2: 0.8878 - val_tp: 4412.0000 - val_tn: 4473.0000 - val_fp2: 560.0000 - val_fn2: 555.0000\n",
      "Epoch 8/20\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1766 - accuracy: 0.9425 - acc_user: 0.9425 - F1score_user: 0.9431 - F1score_user2: 0.9431 - tp: 7158.0000 - tn: 6979.0000 - fp2: 488.0000 - fn2: 375.0000 - val_loss: 0.3740 - val_accuracy: 0.8879 - val_acc_user: 0.8879 - val_F1score_user: 0.8884 - val_F1score_user2: 0.8884 - val_tp: 4464.0000 - val_tn: 4415.0000 - val_fp2: 618.0000 - val_fn2: 503.0000\n",
      "Epoch 9/20\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1728 - accuracy: 0.9454 - acc_user: 0.9454 - F1score_user: 0.9461 - F1score_user2: 0.9461 - tp: 7181.0000 - tn: 7000.0000 - fp2: 467.0000 - fn2: 352.0000 - val_loss: 0.3961 - val_accuracy: 0.8876 - val_acc_user: 0.8876 - val_F1score_user: 0.8859 - val_F1score_user2: 0.8859 - val_tp: 4364.0000 - val_tn: 4512.0000 - val_fp2: 521.0000 - val_fn2: 603.0000\n",
      "Epoch 10/20\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1698 - accuracy: 0.9465 - acc_user: 0.9465 - F1score_user: 0.9472 - F1score_user2: 0.9472 - tp: 7201.0000 - tn: 6996.0000 - fp2: 471.0000 - fn2: 332.0000 - val_loss: 0.3995 - val_accuracy: 0.8857 - val_acc_user: 0.8857 - val_F1score_user: 0.8858 - val_F1score_user2: 0.8858 - val_tp: 4435.0000 - val_tn: 4422.0000 - val_fp2: 611.0000 - val_fn2: 532.0000\n",
      "Epoch 11/20\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1664 - accuracy: 0.9479 - acc_user: 0.9479 - F1score_user: 0.9486 - F1score_user2: 0.9486 - tp: 7207.0000 - tn: 7012.0000 - fp2: 455.0000 - fn2: 326.0000 - val_loss: 0.4124 - val_accuracy: 0.8842 - val_acc_user: 0.8842 - val_F1score_user: 0.8869 - val_F1score_user2: 0.8869 - val_tp: 4539.0000 - val_tn: 4303.0000 - val_fp2: 730.0000 - val_fn2: 428.0000\n",
      "Epoch 12/20\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1632 - accuracy: 0.9498 - acc_user: 0.9498 - F1score_user: 0.9505 - F1score_user2: 0.9505 - tp: 7225.0000 - tn: 7022.0000 - fp2: 445.0000 - fn2: 308.0000 - val_loss: 0.4503 - val_accuracy: 0.8846 - val_acc_user: 0.8846 - val_F1score_user: 0.8828 - val_F1score_user2: 0.8828 - val_tp: 4346.0000 - val_tn: 4500.0000 - val_fp2: 533.0000 - val_fn2: 621.0000\n",
      "Epoch 13/20\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1592 - accuracy: 0.9504 - acc_user: 0.9504 - F1score_user: 0.9511 - F1score_user2: 0.9511 - tp: 7239.0000 - tn: 7017.0000 - fp2: 450.0000 - fn2: 294.0000 - val_loss: 0.4472 - val_accuracy: 0.8836 - val_acc_user: 0.8836 - val_F1score_user: 0.8859 - val_F1score_user2: 0.8859 - val_tp: 4517.0000 - val_tn: 4319.0000 - val_fp2: 714.0000 - val_fn2: 450.0000\n",
      "Epoch 14/20\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1592 - accuracy: 0.9523 - acc_user: 0.9523 - F1score_user: 0.9530 - F1score_user2: 0.9530 - tp: 7247.0000 - tn: 7038.0000 - fp2: 429.0000 - fn2: 286.0000 - val_loss: 0.4644 - val_accuracy: 0.8837 - val_acc_user: 0.8837 - val_F1score_user: 0.8831 - val_F1score_user2: 0.8831 - val_tp: 4391.0000 - val_tn: 4446.0000 - val_fp2: 587.0000 - val_fn2: 576.0000\n",
      "Epoch 15/20\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1565 - accuracy: 0.9539 - acc_user: 0.9539 - F1score_user: 0.9545 - F1score_user2: 0.9545 - tp: 7252.0000 - tn: 7057.0000 - fp2: 410.0000 - fn2: 281.0000 - val_loss: 0.5761 - val_accuracy: 0.8806 - val_acc_user: 0.8806 - val_F1score_user: 0.8774 - val_F1score_user2: 0.8774 - val_tp: 4273.0000 - val_tn: 4533.0000 - val_fp2: 500.0000 - val_fn2: 694.0000\n",
      "Epoch 16/20\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1545 - accuracy: 0.9547 - acc_user: 0.9547 - F1score_user: 0.9553 - F1score_user2: 0.9553 - tp: 7258.0000 - tn: 7062.0000 - fp2: 405.0000 - fn2: 275.0000 - val_loss: 0.5927 - val_accuracy: 0.8805 - val_acc_user: 0.8805 - val_F1score_user: 0.8776 - val_F1score_user2: 0.8776 - val_tp: 4284.0000 - val_tn: 4521.0000 - val_fp2: 512.0000 - val_fn2: 683.0000\n",
      "Epoch 17/20\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1536 - accuracy: 0.9555 - acc_user: 0.9555 - F1score_user: 0.9560 - F1score_user2: 0.9560 - tp: 7265.0000 - tn: 7067.0000 - fp2: 400.0000 - fn2: 268.0000 - val_loss: 0.5446 - val_accuracy: 0.8838 - val_acc_user: 0.8838 - val_F1score_user: 0.8855 - val_F1score_user2: 0.8855 - val_tp: 4493.0000 - val_tn: 4345.0000 - val_fp2: 688.0000 - val_fn2: 474.0000\n",
      "Epoch 18/20\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1531 - accuracy: 0.9567 - acc_user: 0.9567 - F1score_user: 0.9573 - F1score_user2: 0.9573 - tp: 7274.0000 - tn: 7077.0000 - fp2: 390.0000 - fn2: 259.0000 - val_loss: 0.6336 - val_accuracy: 0.8788 - val_acc_user: 0.8788 - val_F1score_user: 0.8766 - val_F1score_user2: 0.8766 - val_tp: 4305.0000 - val_tn: 4483.0000 - val_fp2: 550.0000 - val_fn2: 662.0000\n",
      "Epoch 19/20\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 0.1501 - accuracy: 0.9584 - acc_user: 0.9584 - F1score_user: 0.9589 - F1score_user2: 0.9589 - tp: 7287.0000 - tn: 7089.0000 - fp2: 378.0000 - fn2: 246.0000 - val_loss: 0.6078 - val_accuracy: 0.8803 - val_acc_user: 0.8803 - val_F1score_user: 0.8804 - val_F1score_user2: 0.8804 - val_tp: 4404.0000 - val_tn: 4399.0000 - val_fp2: 634.0000 - val_fn2: 563.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1493 - accuracy: 0.9591 - acc_user: 0.9591 - F1score_user: 0.9596 - F1score_user2: 0.9596 - tp: 7289.0000 - tn: 7097.0000 - fp2: 370.0000 - fn2: 244.0000 - val_loss: 0.6553 - val_accuracy: 0.8780 - val_acc_user: 0.8780 - val_F1score_user: 0.8795 - val_F1score_user2: 0.8795 - val_tp: 4453.0000 - val_tn: 4327.0000 - val_fp2: 706.0000 - val_fn2: 514.0000\n"
     ]
    }
   ],
   "source": [
    "history_new = model_new.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=4, validation_split=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d2ecb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[0.5],[1],[1]], dtype=\"float32\")\n",
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45b78aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[0.5],\n",
       "       [0. ],\n",
       "       [0. ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07bb2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.reduce_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cefc42b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.5>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dedcddb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=int32, numpy=array([0, 1, 0, 1, 1, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.constant([0, 1, 0, 1, 1, 1, 0])\n",
    "c = tf.constant([0, 1, 1, 1, 1, 0, 1])\n",
    "\n",
    "b & c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de5a2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=bool, numpy=array([False,  True, False,  True,  True, False, False])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tf.constant([False, True, False, True, True, True, False], dtype=bool)\n",
    "e = tf.constant([False, True, True, True, True, False, True], dtype=bool)\n",
    "d & e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0ef2d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=bool, numpy=array([False,  True, False,  True,  True, False, False])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.reduce_sum(tf.cast( ((y_pred_classes == 1) and (y_true == 0)), tf.float32))\n",
    "d & e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "685575d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=bool, numpy=array([False,  True,  True,  True,  True, False,  True])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c == 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc4e6cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=bool, numpy=array([ True, False,  True, False, False, False,  True])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1fe02e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=bool, numpy=array([False, False,  True, False, False, False,  True])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c == 1) & (b == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454e293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
