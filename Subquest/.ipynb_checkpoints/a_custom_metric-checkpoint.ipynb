{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677855de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preliminary\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffbc46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load imdb data\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b165cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "# define model\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(4, activation=\"relu\"),\n",
    "        layers.Dense(4, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013965f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eaad330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "    \n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58fc2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"F1score_user\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.predicted_positives = self.add_weight(name=\"predicted_positives\", initializer=\"zeros\") \n",
    "        self.actual_positives = self.add_weight(name=\"actual_positives\", initializer=\"zeros\")\n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.cast(y_pred > 0.5, \"float32\")\n",
    "        y_true = tf.cast(y_true, \"float32\")\n",
    "\n",
    "        actual_positives = tf.reduce_sum(y_true)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        predicted_positives = tf.reduce_sum(y_pred_classes)\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.predicted_positives.assign_add(predicted_positives)     \n",
    "        self.actual_positives.assign_add(actual_positives)     \n",
    "    \n",
    "    def result(self):\n",
    "        precision = ( tf.cast(self.true_positives, tf.float32) \n",
    "              / tf.cast(self.predicted_positives, tf.float32) + tf.keras.backend.epsilon())\n",
    "        recall = ( tf.cast(self.true_positives, tf.float32) \n",
    "              / tf.cast(self.actual_positives, tf.float32) + tf.keras.backend.epsilon())\n",
    "        return  (2 * recall * precision) / (recall + precision + tf.keras.backend.epsilon())\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.predicted_positives.assign(0)\n",
    "        self.actual_positives.assign(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae230f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class acc_user(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"acc_user\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.predicted_positives = self.add_weight(name=\"predicted_positives\", initializer=\"zeros\") \n",
    "        self.actual_positives = self.add_weight(name=\"actual_positives\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"true_negatives\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "#         tp + tn / tp + fp + tn + fn = acc\n",
    "#         tp + fp = p.p\n",
    "#         tp + fn = a.p\n",
    "#         tn \n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.cast(y_pred > 0.5, \"float32\")\n",
    "        y_true = tf.cast(y_true, \"float32\")\n",
    "        \n",
    "        \n",
    "        actual_positives = tf.reduce_sum(y_true)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        predicted_positives = tf.reduce_sum(y_pred_classes)\n",
    "        # false_negatives = tf.reduce_sum(y_true.shape[0] - predicted_positives - (y_true.shape[0]-y_true))\n",
    "        # all samples - p.p - tn\n",
    "        # tn = !y_true\n",
    "        true_negatives = tf.reduce_sum(tf.constant(1, dtype=\"float32\") -y_true)\n",
    "        total_samples = tf.shape(y_pred)[0]\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.predicted_positives.assign_add(predicted_positives)     \n",
    "        self.actual_positives.assign_add(actual_positives)     \n",
    "        self.true_negatives.assign_add(true_negatives)\n",
    "        self.total_samples.assign_add(total_samples)    \n",
    "        \n",
    "    def result(self):\n",
    "\n",
    "        return  (self.true_positives+self.true_negatives)/(tf.cast(self.total_samples, tf.float32) + tf.keras.backend.epsilon())\n",
    "        #return self.total_samples\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.predicted_positives.assign(0)\n",
    "        self.actual_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.total_samples.assign(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b41193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tp(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"tp\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.predicted_positives = self.add_weight(name=\"predicted_positives\", initializer=\"zeros\") \n",
    "        self.actual_positives = self.add_weight(name=\"actual_positives\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"true_negatives\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "#         tp + tn / tp + fp + tn + fn = acc\n",
    "#         tp + fp = p.p\n",
    "#         tp + fn = a.p\n",
    "#         tn \n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.cast(y_pred > 0.5, \"float32\")\n",
    "        y_true = tf.cast(y_true, \"float32\")\n",
    "        \n",
    "        \n",
    "        actual_positives = tf.reduce_sum(y_true)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        predicted_positives = tf.reduce_sum(y_pred_classes)\n",
    "        # false_negatives = tf.reduce_sum(y_true.shape[0] - predicted_positives - (y_true.shape[0]-y_true))\n",
    "        # all samples - p.p - tn\n",
    "        # tn = !y_true\n",
    "        true_negatives = tf.reduce_sum(tf.constant(1, dtype=\"float32\") -y_true)\n",
    "        total_samples = tf.shape(y_pred)[0]\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.predicted_positives.assign_add(predicted_positives)     \n",
    "        self.actual_positives.assign_add(actual_positives)     \n",
    "        self.true_negatives.assign_add(true_negatives)\n",
    "        self.total_samples.assign_add(total_samples)    \n",
    "        \n",
    "    def result(self):\n",
    "\n",
    "        #return  (self.true_positives+self.true_negatives)/(tf.cast(self.total_samples, tf.float32) + tf.keras.backend.epsilon())\n",
    "        return self.true_positives\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.predicted_positives.assign(0)\n",
    "        self.actual_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.total_samples.assign(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c20279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tn(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"tn\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"true_positives\", initializer=\"zeros\")\n",
    "        self.predicted_positives = self.add_weight(name=\"predicted_positives\", initializer=\"zeros\") \n",
    "        self.actual_positives = self.add_weight(name=\"actual_positives\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"true_negatives\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "#         tp + tn / tp + fp + tn + fn = acc\n",
    "#         tp + fp = p.p\n",
    "#         tp + fn = a.p\n",
    "#         tn \n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # For binary classification, threshold predictions at 0.5\n",
    "        y_pred_classes = tf.cast(y_pred > 0.5, \"float32\")\n",
    "        y_true = tf.cast(y_true, \"float32\")\n",
    "        \n",
    "        \n",
    "        actual_positives = tf.reduce_sum(y_true)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred_classes)\n",
    "        predicted_positives = tf.reduce_sum(y_pred_classes)\n",
    "        # false_negatives = tf.reduce_sum(y_true.shape[0] - predicted_positives - (y_true.shape[0]-y_true))\n",
    "        # all samples - p.p - tn\n",
    "        # tn = !y_true\n",
    "        true_negatives = tf.reduce_sum(tf.constant(1, dtype=\"float32\") -y_true)\n",
    "        total_samples = tf.shape(y_pred)[0]\n",
    "        \n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.predicted_positives.assign_add(predicted_positives)     \n",
    "        self.actual_positives.assign_add(actual_positives)     \n",
    "        self.true_negatives.assign_add(true_negatives)\n",
    "        self.total_samples.assign_add(total_samples)    \n",
    "        \n",
    "    def result(self):\n",
    "\n",
    "        #return  (self.true_positives+self.true_negatives)/(tf.cast(self.total_samples, tf.float32) + tf.keras.backend.epsilon())\n",
    "        return self.true_negatives\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.predicted_positives.assign(0)\n",
    "        self.actual_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.total_samples.assign(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de1cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_new = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "439e890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                 metrics=[\"accuracy\", acc_user(), F1Score(), tp(), tn()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7b8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 0.3462 - accuracy: 0.8607 - acc_user: 15000.0000 - F1score_user: 0.8620 - tp: 6526.0000 - tn: 7467.0000 - val_loss: 0.3189 - val_accuracy: 0.8744 - val_acc_user: 10000.0000 - val_F1score_user: 0.8656 - val_tp: 4046.0000 - val_tn: 5033.0000\n",
      "Epoch 2/20\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.2388 - accuracy: 0.9119 - acc_user: 15000.0000 - F1score_user: 0.9127 - tp: 6913.0000 - tn: 7467.0000 - val_loss: 0.3311 - val_accuracy: 0.8796 - val_acc_user: 10000.0000 - val_F1score_user: 0.8722 - val_tp: 4109.0000 - val_tn: 5033.0000\n",
      "Epoch 3/20\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.2134 - accuracy: 0.9233 - acc_user: 15000.0000 - F1score_user: 0.9239 - tp: 6990.0000 - tn: 7467.0000 - val_loss: 0.3211 - val_accuracy: 0.8896 - val_acc_user: 10000.0000 - val_F1score_user: 0.8868 - val_tp: 4326.0000 - val_tn: 5033.0000\n",
      "Epoch 4/20\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.1985 - accuracy: 0.9286 - acc_user: 15000.0000 - F1score_user: 0.9292 - tp: 7026.0000 - tn: 7467.0000 - val_loss: 0.3419 - val_accuracy: 0.8871 - val_acc_user: 10000.0000 - val_F1score_user: 0.8905 - val_tp: 4593.0000 - val_tn: 5033.0000\n",
      "Epoch 5/20\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.1881 - accuracy: 0.9346 - acc_user: 15000.0000 - F1score_user: 0.9350 - tp: 7059.0000 - tn: 7467.0000 - val_loss: 0.3396 - val_accuracy: 0.8897 - val_acc_user: 10000.0000 - val_F1score_user: 0.8867 - val_tp: 4317.0000 - val_tn: 5033.0000\n",
      "Epoch 6/20\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.1797 - accuracy: 0.9366 - acc_user: 15000.0000 - F1score_user: 0.9370 - tp: 7075.0000 - tn: 7467.0000 - val_loss: 0.3526 - val_accuracy: 0.8868 - val_acc_user: 10000.0000 - val_F1score_user: 0.8829 - val_tp: 4268.0000 - val_tn: 5033.0000\n",
      "Epoch 7/20\n",
      " 120/3750 [..............................] - ETA: 6s - loss: 0.1970 - accuracy: 0.9292 - acc_user: 480.0000 - F1score_user: 0.9289 - tp: 222.0000 - tn: 240.0000"
     ]
    }
   ],
   "source": [
    "history_new = model_new.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=4, validation_split=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[0.5],[1],[1]], dtype=\"float32\")\n",
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af154e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0281bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.reduce_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c11cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd6877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
